{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eeae81f",
   "metadata": {},
   "source": [
    "## Pip install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5f9791-3822-4cfe-9bd8-d2452ac8327a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index\n",
    "!pip install llama-index-core==0.10.6.post1\n",
    "!pip install llama-index-postprocessor-flag-embedding-reranker\n",
    "!pip install git+https://github.com/FlagOpen/FlagEmbedding.git\n",
    "!pip install llama-parse\n",
    "%pip install -U llama-index llama-index-embeddings-nomic\n",
    "%pip install llama-index-llms-ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ede4e83",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e28df526-cc86-4678-a83d-6c411e9d5e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llama-parse is async-first, running the async code in a notebook requires the use of nest_asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.nomic import NomicEmbedding\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8f50390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the Nomic API key\n",
    "nomic_api_key = os.getenv(\"NOMIC_API_KEY\")\n",
    "\n",
    "# Access to Llama-cloud API Key\n",
    "llama_cloud_api_key = os.getenv(\"LLAMA_CLOUD_API_KEY\")\n",
    "\n",
    "\n",
    "llm = Ollama(model=\"llama3.1:latest\", request_timeout=120.0)\n",
    "embed_model = NomicEmbedding(\n",
    "    api_key=nomic_api_key,\n",
    "    dimensionality=128,\n",
    "    model_name=\"nomic-embed-text-v1.5\",\n",
    ")\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f5029fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id a1980be9-5742-4bf9-b1b8-99ed1f48dc8e\n"
     ]
    }
   ],
   "source": [
    "from llama_parse import LlamaParse\n",
    "\n",
    "documents = LlamaParse(result_type=\"markdown\").load_data(\"/Users/angelmurillo/Desktop/OpenSource_RAG_LLM/data/AVD-005-MAB_INT_VIAL_RELEASE_1.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dda9b696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Lonzzo\\n\\n# Batch Report\\n\\n# Batch Header Information\\n\\nOrder Number: AVD-005-MAB_INT_VIAL_RELEASE_1\\n\\nQuantity: 1 PC\\n\\nVersion: 23\\n\\nProduct: (MC1S1_000010) MR_INT_VIAL_RELEASE_T\\n\\nRecipe: (MR_INT_VIAL_RELEASE_T)\\n\\nWD Start: EWI Start: 27-Jul-2023\\n\\nEWI End: 27-Jul-2023\\n\\nOrder Signoff: 27-Jul-2023\\n\\n08:28:42 09:32:35 09:33:54\\n\\n# Table of Contents\\n\\n- Review Signatures\\n- Critical / Other / Spez Parameters\\n- Recipe Signatures (Non-Instruction)\\n- Comments\\n- Attachments\\n- Bill of Materials\\n- Output Materials\\n- Samples\\n- Trends of Critical / Other Process Parameters\\n- Instructions\\n\\n# Linked Workflows - Table of Contents\\n\\nNone\\n\\n# Review Signatures - Table of Contents\\n\\nNone\\n\\n# QA Signature\\n\\nNone\\n\\n# Order Review Signature\\n\\n|Name|Date|\\n|---|---|\\n|system (System Account)|27-Jul-2023 09:33:52|\\n\\n# Last Approval Signature\\n\\n|Name|Date|\\n|---|---|\\n|system (System Account)|27-Jul-2023 09:33:54|\\n\\nAVD-005-MAB_INT_VIAL_RELEASE_1 Page 1 of 26'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28616ea7",
   "metadata": {},
   "source": [
    "# Setting up Reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a0d0195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "323b4ec526a94eb3b1ed7212948669cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e18cefdcf9428a8e6d0c3105681a08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23ecbe2f743844e8b7bd5434b725da6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac2b79bbf21d43f2b956e92bc3af8595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/279 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea558751df6c47a4a9fc1a62488e8616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/801 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2491bb612e44483bbf50fd6ee1d6175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.postprocessor.flag_embedding_reranker import FlagEmbeddingReranker\n",
    "\n",
    "reranker = FlagEmbeddingReranker(\n",
    "    top_n=5,\n",
    "    model=\"BAAI/bge-reranker-large\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7361667",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "reader = SimpleDirectoryReader(input_files=[\"/Users/angelmurillo/Desktop/OpenSource_RAG_LLM/data/AVD-005-MAB_INT_VIAL_RELEASE_1.pdf\"])\n",
    "base_docs = reader.load_data()\n",
    "raw_index = VectorStoreIndex.from_documents(base_docs)\n",
    "raw_query_engine = raw_index.as_query_engine(\n",
    "    similarity_top_k=5, node_postprocessors=[reranker]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c18a173",
   "metadata": {},
   "source": [
    "## Testing Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a262c4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***********Basic Query Engine***********\n",
      "AV0122\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the cell line name\"\n",
    "\n",
    "response_1 = raw_query_engine.query(query)\n",
    "print(\"\\n***********Basic Query Engine***********\")\n",
    "print(response_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1fb27b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***********Basic Query Engine***********\n",
      "1218 -W.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the cell bank ID?\"\n",
    "\n",
    "response_1 = raw_query_engine.query(query)\n",
    "print(\"\\n***********Basic Query Engine***********\")\n",
    "print(response_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dc6603",
   "metadata": {},
   "source": [
    "## Using Redis to cache prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c9e1135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "import hashlib\n",
    "import json\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.core.postprocessor import SentenceTransformerRerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db9d5db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Redis connection\n",
    "\n",
    "redis_client = redis.Redis(\n",
    "  host='redis-13600.c274.us-east-1-3.ec2.redns.redis-cloud.com',\n",
    "  port=13600,\n",
    "  password='k2WbUc23FzUf4x3Kgb3qDJ40NeCAu6Lr')\n",
    "\n",
    "# Set up RAG components\n",
    "reader = SimpleDirectoryReader(input_files=[\"/Users/angelmurillo/Desktop/OpenSource_RAG_LLM/data/AVD-005-MAB_INT_VIAL_RELEASE_1.pdf\"])\n",
    "base_docs = reader.load_data()\n",
    "raw_index = VectorStoreIndex.from_documents(base_docs)\n",
    "reranker = reranker\n",
    "raw_query_engine = raw_index.as_query_engine(\n",
    "    similarity_top_k=5, node_postprocessors=[reranker]\n",
    ")\n",
    "\n",
    "def get_cache_key(query):\n",
    "    # Create a unique key based on the query\n",
    "    return hashlib.md5(query.encode()).hexdigest()\n",
    "\n",
    "def get_cached_result(query):\n",
    "    cache_key = get_cache_key(query)\n",
    "    cached_result = redis_client.get(cache_key)\n",
    "    if cached_result:\n",
    "        return json.loads(cached_result)\n",
    "    return None\n",
    "\n",
    "def set_cached_result(query, result, expiration_time=3600):\n",
    "    cache_key = get_cache_key(query)\n",
    "    redis_client.setex(cache_key, expiration_time, json.dumps(result))\n",
    "\n",
    "def process_query(query):\n",
    "    # Check if result is in cache\n",
    "    cached_result = get_cached_result(query)\n",
    "    if cached_result:\n",
    "        print(\"Cache hit!\")\n",
    "        return cached_result\n",
    "\n",
    "    # If not in cache, perform the query processing\n",
    "    print(\"Cache miss. Processing query...\")\n",
    "    result = raw_query_engine.query(query)\n",
    "\n",
    "    # Convert the result to a serializable format\n",
    "    serializable_result = {\n",
    "        'response': str(result.response),\n",
    "        'source_nodes': [\n",
    "            {\n",
    "                'node_id': node.node.node_id,\n",
    "                'score': node.score,\n",
    "                'text': node.node.text,\n",
    "            } for node in result.source_nodes\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Cache the result\n",
    "    set_cached_result(query, serializable_result)\n",
    "\n",
    "    return serializable_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "349ecae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache miss. Processing query...\n",
      "The generation number.\n",
      "Cache hit!\n",
      "The generation number.\n"
     ]
    }
   ],
   "source": [
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"From the cell bank information, what is the generation number?\"\n",
    "\n",
    "    # First query - should be a cache miss\n",
    "    result = process_query(query)\n",
    "    print(result['response'])\n",
    "\n",
    "    # Second query with the same parameters - should be a cache hit\n",
    "    result = process_query(query)\n",
    "    print(result['response'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
